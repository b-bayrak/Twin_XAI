{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp_3_MAS_explains_BB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import joblib\n",
    "\n",
    "import api_calls\n",
    "from api_calls import *\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "#from pandas import json_normalize\n",
    "import warnings\n",
    "import requests\n",
    "from requests import get\n",
    "import time\n",
    "\n",
    "from mycbr_py_api import MyCBRRestApi as mycbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Variables that are related to current CBR project\n",
    "concept = 'case' \n",
    "\n",
    "# API connection\n",
    "\n",
    "server = 'localhost'\n",
    "#server = 'user@hv-6066.idi.ntnu.no'\n",
    "\n",
    "port = '8080'\n",
    "base_url = 'http://' + server + ':' + port + '/'\n",
    "\n",
    "headers = {'Content-type':'application/json'}\n",
    "\n",
    "obj = mycbr(base_url)\n",
    "\n",
    "# Confidence scores of CBR agents \n",
    "#(Confidence valeus calculated in exp_2 and treshold value determined manually according to system performance)\n",
    "confidence = [0.62, 0.57, 0.33]\n",
    "conf_tresh = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data \n",
    "train = pd.read_csv('./data/train_matched.csv', index_col=0) \n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "train_X, train_y = train.drop(['Target'],axis=1), train['Target']\n",
    "test_X, test_y = test.drop(['Target'],axis=1), test['Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load black-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_model = joblib.load(\"./model/MLP_oversampled.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build 3 agents CBR system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cases deleted from case: True\n"
     ]
    }
   ],
   "source": [
    "# Delete all cases\n",
    "delete_instances_from_concept(concept)\n",
    "\n",
    "# Group test samples up to classes\n",
    "train_class0 = train.loc[train.Target == 0]\n",
    "train_class1 = train.loc[train.Target == 1]\n",
    "train_class2 = train.loc[train.Target == 2]\n",
    "\n",
    "# Adding cases to respective casebases\n",
    "add_cases_from_df(train_class0, concept, 'cb_class0')    \n",
    "add_cases_from_df(train_class1, concept, 'cb_class1')    \n",
    "add_cases_from_df(train_class2, concept, 'cb_class2')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read shap values to create amalgamation functuions\n",
    "shap_c0 = pd.read_csv('./shap_values/c0.csv', index_col=[0]) \n",
    "shap_c1 = pd.read_csv('./shap_values/c1.csv', index_col=[0])\n",
    "shap_c2 = pd.read_csv('./shap_values/c2.csv', index_col=[0])\n",
    "\n",
    "matched_booster = 15\n",
    "shap_c0 = shap_c0.append(pd.DataFrame({'shap':shap_c0.max().item()*matched_booster},index=['Matched']))\n",
    "shap_c1 = shap_c1.append(pd.DataFrame({'shap':shap_c1.max().item()*matched_booster},index=['Matched']))\n",
    "shap_c2 = shap_c2.append(pd.DataFrame({'shap':shap_c2.max().item()*matched_booster},index=['Matched']))\n",
    "\n",
    "# Cast shap values to string for creating json objects (for newAmalgamationFunc)\n",
    "str_map0 = str(shap_c0.to_dict()['shap']).replace(\"'\",'\"')\n",
    "str_map1 = str(shap_c1.to_dict()['shap']).replace(\"'\",'\"')\n",
    "str_map2 = str(shap_c2.to_dict()['shap']).replace(\"'\",'\"')\n",
    "\n",
    "# Set amalgamation functions for each casebase\n",
    "newAmalgamationFunc('case','amal_func_class0', 'WEIGHTED_SUM', str_map0)\n",
    "newAmalgamationFunc('case','amal_func_class1', 'WEIGHTED_SUM', str_map1)\n",
    "newAmalgamationFunc('case','amal_func_class2', 'WEIGHTED_SUM', str_map2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_cases(df):\n",
    "    c0= obj.getCaseByCaseID(df.caseID_c0[0],concept,'cb_class0')\n",
    "    c0['Class'] = 0\n",
    "    c0['Similarity'] = df.similarity_c0[0]\n",
    "    c0['Support'] = None\n",
    "\n",
    "    c1 = obj.getCaseByCaseID(df.caseID_c1[0],concept,'cb_class1')\n",
    "    c1['Class'] = 1\n",
    "    c1['Similarity'] = df.similarity_c1[0]\n",
    "    c1['Support'] = None\n",
    "\n",
    "    c2 = obj.getCaseByCaseID(df.caseID_c2[0],concept,'cb_class2')\n",
    "    c2['Class'] = 2\n",
    "    c2['Similarity'] = df.similarity_c2[0]\n",
    "    c2['Support'] = None\n",
    "\n",
    "    res = c0\n",
    "    res = res.append([c1,c2])\n",
    "    return res.reset_index()\n",
    "\n",
    "\n",
    "# row is a test sample (without Target)\n",
    "def comparison(row):\n",
    "    # Prediction of model\n",
    "    bb_pred =  bb_model.predict([row])[0]\n",
    "    \n",
    "    # query the case in 3 cb\n",
    "    row['Matched'] = calculateMatched(row)\n",
    "    cbr_sim = query_all_cbr_systems(concept,  row, k=1)\n",
    "    # Retrieve closest cases from cb\n",
    "    cases = retrieve_cases(cbr_sim)\n",
    "    # Cbr prediction result\n",
    "    cbr_pred = get_class_from_cbr_results(cbr_sim.loc[0])\n",
    "    \n",
    "\n",
    "    # Return a Contrastive or Supportive explanation case \n",
    "    exp_case = pd.DataFrame()\n",
    "    if bb_pred != cbr_pred and confidence[cbr_pred] > conf_tresh:\n",
    "        exp_case = cases.loc[cbr_pred]\n",
    "        exp_case.Support = 'Contrastive'\n",
    "    else: \n",
    "        exp_case = cases.loc[bb_pred]\n",
    "        exp_case.Support = 'Supportive'\n",
    "\n",
    "    exp_case['bb'] = bb_pred\n",
    "    \n",
    "    return exp_case.drop(['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- Query_0 -------------------\n",
      "The Black-box predicts class 1\n",
      "The Multi-Agent CBR system returns \"case_9\" with a similarity score 0.911 as a CONTRASTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_1 -------------------\n",
      "The Black-box predicts class 2\n",
      "The Multi-Agent CBR system returns \"case_46\" with a similarity score 0.898 as a CONTRASTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_2 -------------------\n",
      "The Black-box predicts class 2\n",
      "The Multi-Agent CBR system returns \"case_67\" with a similarity score 0.901 as a CONTRASTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_3 -------------------\n",
      "The Black-box predicts class 2\n",
      "The Multi-Agent CBR system returns \"case_2\" with a similarity score 0.908 as a CONTRASTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_4 -------------------\n",
      "The Black-box predicts class 2\n",
      "The Multi-Agent CBR system returns \"case_28\" with a similarity score 0.917 as a SUPPORTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_5 -------------------\n",
      "The Black-box predicts class 1\n",
      "The Multi-Agent CBR system returns \"case_42\" with a similarity score 0.882 as a SUPPORTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_6 -------------------\n",
      "The Black-box predicts class 1\n",
      "The Multi-Agent CBR system returns \"case_71\" with a similarity score 0.960 as a CONTRASTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_7 -------------------\n",
      "The Black-box predicts class 0\n",
      "The Multi-Agent CBR system returns \"case_42\" with a similarity score 0.931 as a CONTRASTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_8 -------------------\n",
      "The Black-box predicts class 2\n",
      "The Multi-Agent CBR system returns \"case_31\" with a similarity score 0.893 as a CONTRASTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_9 -------------------\n",
      "The Black-box predicts class 0\n",
      "The Multi-Agent CBR system returns \"case_22\" with a similarity score 0.927 as a SUPPORTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_10 -------------------\n",
      "The Black-box predicts class 0\n",
      "The Multi-Agent CBR system returns \"case_18\" with a similarity score 0.889 as a SUPPORTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_11 -------------------\n",
      "The Black-box predicts class 0\n",
      "The Multi-Agent CBR system returns \"case_60\" with a similarity score 0.905 as a SUPPORTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_12 -------------------\n",
      "The Black-box predicts class 0\n",
      "The Multi-Agent CBR system returns \"case_63\" with a similarity score 0.949 as a SUPPORTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_13 -------------------\n",
      "The Black-box predicts class 0\n",
      "The Multi-Agent CBR system returns \"case_69\" with a similarity score 0.931 as a CONTRASTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_14 -------------------\n",
      "The Black-box predicts class 2\n",
      "The Multi-Agent CBR system returns \"case_62\" with a similarity score 0.898 as a CONTRASTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_15 -------------------\n",
      "The Black-box predicts class 0\n",
      "The Multi-Agent CBR system returns \"case_44\" with a similarity score 0.915 as a CONTRASTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_16 -------------------\n",
      "The Black-box predicts class 1\n",
      "The Multi-Agent CBR system returns \"case_63\" with a similarity score 0.952 as a CONTRASTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_17 -------------------\n",
      "The Black-box predicts class 0\n",
      "The Multi-Agent CBR system returns \"case_2\" with a similarity score 0.901 as a SUPPORTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_18 -------------------\n",
      "The Black-box predicts class 1\n",
      "The Multi-Agent CBR system returns \"case_67\" with a similarity score 0.879 as a SUPPORTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_19 -------------------\n",
      "The Black-box predicts class 1\n",
      "The Multi-Agent CBR system returns \"case_81\" with a similarity score 0.917 as a SUPPORTIVE case.\n",
      "\n",
      "\n",
      "------------------- Query_20 -------------------\n",
      "The Black-box predicts class 1\n",
      "The Multi-Agent CBR system returns \"case_46\" with a similarity score 0.905 as a SUPPORTIVE case.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(test)):\n",
    "    exp = comparison(test_X.loc[idx])\n",
    "    print('------------------- Query_{} -------------------'.format(idx))\n",
    "    print('The Black-box predicts class {}'.format(exp.bb))\n",
    "    print('The Multi-Agent CBR system returns \"{}\" with a similarity score {:.3f} as a {} case.\\n\\n'.format(exp.caseID, exp.Similarity, exp.Support.upper()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the query  with the most similar case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes that differ between the query and the most similar case\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t4</th>\n",
       "      <th>t9</th>\n",
       "      <th>t13</th>\n",
       "      <th>t15</th>\n",
       "      <th>t41</th>\n",
       "      <th>t46</th>\n",
       "      <th>t51</th>\n",
       "      <th>t55</th>\n",
       "      <th>t63</th>\n",
       "      <th>t64</th>\n",
       "      <th>t66</th>\n",
       "      <th>t73</th>\n",
       "      <th>t100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>query</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similar case</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               t4   t9  t13  t15  t41  t46  t51  t55  t63  t64  t66  t73  t100\n",
       "query         0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "similar case  1.0  1.0  1.0  0.0  1.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0   1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 16\n",
    "\n",
    "exp = comparison(test_X.loc[idx])\n",
    "exp2 = pd.DataFrame(exp.drop(['Matched','caseID','Class','Support'])).T\n",
    "q = pd.DataFrame(test_X.loc[idx]).T\n",
    "q = q.astype(float)\n",
    "exp2 = exp2.astype(float)\n",
    "\n",
    "res = q.append(exp2)\n",
    "res.index = ['query','similar case']\n",
    "\n",
    "print('Attributes that differ between the query and the most similar case')\n",
    "res[res.diff() != 0].dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes that are the same for the query and the most similar case\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t0</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t5</th>\n",
       "      <th>t6</th>\n",
       "      <th>t7</th>\n",
       "      <th>t8</th>\n",
       "      <th>t10</th>\n",
       "      <th>t11</th>\n",
       "      <th>...</th>\n",
       "      <th>t91</th>\n",
       "      <th>t92</th>\n",
       "      <th>t93</th>\n",
       "      <th>t94</th>\n",
       "      <th>t95</th>\n",
       "      <th>t96</th>\n",
       "      <th>t97</th>\n",
       "      <th>t98</th>\n",
       "      <th>t99</th>\n",
       "      <th>t101</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>query</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similar case</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               t0   t1   t2   t3   t5   t6   t7   t8  t10  t11  ...  t91  t92  \\\n",
       "query         0.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "similar case  0.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "              t93  t94  t95  t96  t97  t98  t99  t101  \n",
       "query         0.0  1.0  0.0  0.0  1.0  0.0  1.0   1.0  \n",
       "similar case  0.0  1.0  0.0  0.0  1.0  0.0  1.0   1.0  \n",
       "\n",
       "[2 rows x 91 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Attributes that are the same for the query and the most similar case')\n",
    "res[res.diff() != 1].dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete comparison of query and the most similar case\n"
     ]
    }
   ],
   "source": [
    "print('Complete comparison of query and the most similar case')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.set(rc = {'figure.figsize':(30,2)})\n",
    "sns.heatmap(res.drop(['Similarity', 'bb'], axis = 1), cmap='plasma', cbar=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
